{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(len(acc)), acc, label='Training Accuracy')\n",
    "    plt.plot(range(len(val_acc)), val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(len(loss)), loss, label='Training Loss')\n",
    "    plt.plot(range(len(val_loss)), val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 64\n",
    "IMG_WIDTH = 64\n",
    "EPOCHS = 25\n",
    "DATA_DIR_PATH = \"../input/trees-in-satellite-imagery/Trees in Satellite Imagery\"\n",
    "\n",
    "num_parameters_time = {}\n",
    "num_parameters_accuracy = {}\n",
    "num_parameters = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET = tf.keras.utils.image_dataset_from_directory(\n",
    "  DATA_DIR_PATH,\n",
    "  validation_split=0.1,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "  batch_size=BATCH_SIZE)\n",
    "\n",
    "VALIDATION_DATASET = tf.keras.utils.image_dataset_from_directory(\n",
    "  DATA_DIR_PATH,\n",
    "  validation_split=0.1,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "  batch_size=BATCH_SIZE)\n",
    "\n",
    "CLASS_NAMES = TRAIN_DATASET.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in TRAIN_DATASET.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(CLASS_NAMES[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(len(CLASS_NAMES))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "\n",
    "history = model.fit(\n",
    "  TRAIN_DATASET,\n",
    "  validation_data=VALIDATION_DATASET,\n",
    "  epochs=EPOCHS\n",
    ")\n",
    "\n",
    "end = time()\n",
    "\n",
    "elapsed_time = end - start\n",
    "\n",
    "print(f\"Elapsed Time:{elapsed_time}s\")\n",
    "\n",
    "\n",
    "num_parameters[\"Base\"] = 548258\n",
    "num_parameters_time[\"Base\"] = elapsed_time\n",
    "num_parameters_accuracy[\"Base\"] = history.history[\"val_accuracy\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET = tf.keras.utils.image_dataset_from_directory(\n",
    "  DATA_DIR_PATH,\n",
    "  validation_split=0.1,\n",
    "  subset=\"training\",\n",
    "  color_mode=\"grayscale\",\n",
    "  seed=123,\n",
    "  image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "  batch_size=BATCH_SIZE)\n",
    "\n",
    "VALIDATION_DATASET = tf.keras.utils.image_dataset_from_directory(\n",
    "  DATA_DIR_PATH,\n",
    "  validation_split=0.1,\n",
    "  subset=\"validation\",\n",
    "  color_mode=\"grayscale\",\n",
    "  seed=123,\n",
    "  image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in TRAIN_DATASET.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(CLASS_NAMES[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(len(CLASS_NAMES))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "\n",
    "history = model.fit(\n",
    "  TRAIN_DATASET,\n",
    "  validation_data=VALIDATION_DATASET,\n",
    "  epochs=EPOCHS\n",
    ")\n",
    "\n",
    "end = time()\n",
    "\n",
    "elapsed_time = end - start\n",
    "\n",
    "print(f\"Elapsed Time:{elapsed_time}s\")\n",
    "\n",
    "num_parameters[\"Grayscale\"] = 547970\n",
    "num_parameters_time[\"Grayscale\"] = elapsed_time\n",
    "num_parameters_accuracy[\"Grayscale\"] = history.history[\"val_accuracy\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(len(CLASS_NAMES))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "\n",
    "history = model.fit(\n",
    "  TRAIN_DATASET,\n",
    "  validation_data=VALIDATION_DATASET,\n",
    "  epochs=EPOCHS\n",
    ")\n",
    "\n",
    "end = time()\n",
    "\n",
    "elapsed_time = end - start\n",
    "\n",
    "print(f\"Elapsed Time:{elapsed_time}s\")\n",
    "\n",
    "num_parameters[\"One Conv2D layer with 16 output filters\"] = 2097698\n",
    "num_parameters_time[\"One Conv2D layer with 16 output filters\"] = elapsed_time\n",
    "num_parameters_accuracy[\"One Conv2D layer with 16 output filters\"] = history.history[\"val_accuracy\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
    "  layers.Conv2D(4, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(len(CLASS_NAMES))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "\n",
    "history = model.fit(\n",
    "  TRAIN_DATASET,\n",
    "  validation_data=VALIDATION_DATASET,\n",
    "  epochs=EPOCHS\n",
    ")\n",
    "\n",
    "end = time()\n",
    "\n",
    "elapsed_time = end - start\n",
    "\n",
    "print(f\"Elapsed Time:{elapsed_time}s\")\n",
    "\n",
    "num_parameters[\"One Conv2D layer with 4 output filters\"] = 524714\n",
    "num_parameters_time[\"One Conv2D layer with 4 output filters\"] = elapsed_time\n",
    "num_parameters_accuracy[\"One Conv2D layer with 4 output filters\"] = history.history[\"val_accuracy\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  layers.Conv2D(4, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(32, activation='relu'),\n",
    "  layers.Dense(len(CLASS_NAMES))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "\n",
    "history = model.fit(\n",
    "  TRAIN_DATASET,\n",
    "  validation_data=VALIDATION_DATASET,\n",
    "  epochs=EPOCHS\n",
    ")\n",
    "\n",
    "end = time()\n",
    "\n",
    "elapsed_time = end - start\n",
    "\n",
    "print(f\"Elapsed Time:{elapsed_time}s\")\n",
    "\n",
    "num_parameters[\"One Conv2D layer with 4 output filters and less dense neurons\"] = 131210\n",
    "num_parameters_time[\"One Conv2D layer with 4 output filters and less dense neurons\"] = elapsed_time\n",
    "num_parameters_accuracy[\"One Conv2D layer with 4 output filters and less dense neurons\"] = history.history[\"val_accuracy\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame({\n",
    "    \"Model Name\": list(num_parameters.keys()),\n",
    "    \"# Trainable Parameters\": list(num_parameters.values()),\n",
    "    \"Training Time (seconds)\": list(num_parameters_time.values()),\n",
    "    \"Validation Accuracy\": list(num_parameters_accuracy.values()),\n",
    "})\n",
    "\n",
    "dataframe[\"Average Time per Epoch\"] =  dataframe[\"Training Time (seconds)\"]/EPOCHS\n",
    "\n",
    "dataframe"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
